import streamlit as st
from langchain.memory import ConversationBufferMemory
from utils3 import qa_agent
from utils2 import get_chat_response

def main():
    st.title("ğŸ“‘ AIçŸ¥è¯†åº“å°åŠ©æ‰‹")

    with st.sidebar:
        openai_api_key = st.text_input("è¯·è¾“å…¥dashscope apiå¯†é’¥ï¼š", type="password")
        base_url = st.text_input("base_urlï¼š", type="password")
        st.markdown("[è·å–dashscope api key](https://account.aliyun.com/)")

    selected_method = st.radio(
        "ä½ æƒ³é€‰æ‹©å“ªç§æ¨¡å¼è¿›è¡Œå¯¹è¯ï¼Ÿ",
        ["None", "chat_qa_chain"],
        captions=["ä¸ä½¿ç”¨æ£€ç´¢é—®ç­”çš„æ™®é€šæ¨¡å¼", "å¸¦å†å²è®°å½•çš„æ£€ç´¢é—®ç­”æ¨¡å¼"])
    if selected_method == "None":
        if "memory" not in st.session_state:
            st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
            st.session_state["messages"] = [{"role": "ai",
                                             "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"}]

        for message in st.session_state["messages"]:
            st.chat_message(message["role"]).write(message["content"])

        prompt = st.chat_input()
        if prompt:
            if not openai_api_key:
                st.info("è¯·è¾“å…¥ä½ çš„OpenAI API Key")
                st.stop()
            st.session_state["messages"].append({"role": "human", "content": prompt})
            st.chat_message("human").write(prompt)

            with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
                response = get_chat_response(prompt, st.session_state["memory"],
                                             openai_api_key, base_url)
            msg = {"role": "ai", "content": response}
            st.session_state["messages"].append(msg)
            st.chat_message("ai").write(response)


    elif selected_method == "chat_qa_chain":
        if "memory1" not in st.session_state:
            st.session_state["memory1"] = ConversationBufferMemory(
                return_messages=True,
                memory_key="chat_history",
                output_key="answer"
            )

        uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„PDFæ–‡ä»¶ï¼š", type="pdf")
        question = st.text_input("å¯¹PDFçš„å†…å®¹è¿›è¡Œæé—®", disabled=not uploaded_file)

        if uploaded_file and question and not openai_api_key:
            st.info("è¯·è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥")

        if uploaded_file and question and openai_api_key:
            with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
                response = qa_agent(openai_api_key, st.session_state["memory1"],
                                    uploaded_file, question, base_url)
            st.write("### ç­”æ¡ˆ")
            st.write(response["answer"])
            st.session_state["chat_history"] = response["chat_history"]

        if "chat_history" in st.session_state:
            with st.expander("å†å²æ¶ˆæ¯"):
                for i in range(0, len(st.session_state["chat_history"]), 2):
                    human_message = st.session_state["chat_history"][i]
                    ai_message = st.session_state["chat_history"][i + 1]
                    st.write(human_message.content)
                    st.write(ai_message.content)
                    if i < len(st.session_state["chat_history"]) - 2:
                        st.divider()

if __name__ == "__main__":
    main()